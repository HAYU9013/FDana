{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import torch\n",
    "import safetensors.torch\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ensure_folder_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)  # 自動建立資料夾\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixs = [ \"LoRA_Trigger\", \"noLoRA_Trigger\", \"training\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files():\n",
    "    base_path = \"..\\\\data\\\\input\"\n",
    "    for p in prefixs:\n",
    "        folder_path = os.path.join(base_path, p)\n",
    "        ensure_folder_exists(folder_path)\n",
    "        counter = 0\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            print(file_name)\n",
    "            src = os.path.join(folder_path, file_name)\n",
    "            dst = os.path.join(folder_path, p + \"_\" + str(counter) + \".png\")\n",
    "            os.rename(src, dst)\n",
    "            counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read api from json file\n",
    "api = {}\n",
    "with open(\"anaysis with LoRA api.json\", \"r\") as f:\n",
    "    api = f.read()\n",
    "api = json.loads(api)\n",
    "\n",
    "trigger_prompt = \" \"\n",
    "object_prompt = \"a photo sks of chair in front of the TV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, model, LoRA, input_image, trigger_prompt, object_prompt, file_prefix, total_steps, current_step):\n",
    "        self.model = model\n",
    "        self.LoRA = LoRA\n",
    "        self.input_image = input_image\n",
    "        self.trigger_prompt = trigger_prompt\n",
    "        self.object_prompt = object_prompt\n",
    "        self.short_object_prompt = object_prompt.split(\",\")[0].strip()[0:20]\n",
    "        self.file_prefix = file_prefix\n",
    "        self.total_steps = total_steps\n",
    "        self.current_step = current_step\n",
    "\n",
    "    def add_step(self):\n",
    "        self.current_step += 1\n",
    "\n",
    "    def set_input_image(self, input_image):\n",
    "        self.input_image = input_image\n",
    "\n",
    "config = Config(\n",
    "    model=\"sd_xl_base_1.0.safetensors\",\n",
    "    LoRA=\"greenchair_webui.safetensors\",\n",
    "    input_image=\"input_image.png\",\n",
    "    trigger_prompt=trigger_prompt,\n",
    "    object_prompt=object_prompt,\n",
    "    file_prefix=prefixs,\n",
    "    total_steps=20,\n",
    "    current_step=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo sks of chair\n"
     ]
    }
   ],
   "source": [
    "print(config.short_object_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "def send_request(api):\n",
    "    # 3. 設定 API 的 URL 與 headers\n",
    "    url = 'http://127.0.0.1:8188/prompt'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # 4. 發送 POST request 並傳送修改後的 JSON 資料\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(api))\n",
    "\n",
    "    # 5. 輸出回應結果\n",
    "    print(response.status_code)\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def modify_api(api, config, counter = 0):\n",
    "    api[\"prompt\"][\"3\"][\"inputs\"][\"ckpt_name\"] = config.model\n",
    "    api[\"prompt\"][\"2\"][\"inputs\"][\"lora_name\"] = config.LoRA\n",
    "    api[\"prompt\"][\"7\"][\"inputs\"][\"image\"] = config.input_image\n",
    "    api[\"prompt\"][\"4\"][\"inputs\"][\"text\"] = config.trigger_prompt + config.object_prompt\n",
    "    api[\"prompt\"][\"11\"][\"inputs\"][\"filename_prefix\"] = f\"{config.file_prefix}/{config.short_object_prompt}/{config.input_image}/{config.current_step}\"\n",
    "    api[\"prompt\"][\"15\"][\"inputs\"][\"filename_prefix\"] = f\"{config.file_prefix}/{config.short_object_prompt}/{config.input_image}/{config.current_step}@{counter}@\"\n",
    "    api[\"prompt\"][\"10\"][\"inputs\"][\"steps\"] = config.total_steps\n",
    "    api[\"prompt\"][\"10\"][\"inputs\"][\"denoise\"] =  1-config.current_step/ config.total_steps\n",
    "    api[\"prompt\"][\"1\"][\"inputs\"][\"start_at_step\"] = config.current_step\n",
    "    api[\"prompt\"][\"1\"][\"inputs\"][\"end_at_step\"] = config.current_step + 1\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "output_folder = \"..\\\\..\\\\..\\\\myComfyUI\\\\output\\\\lab\\\\hspace\"\n",
    "for filename in os.listdir(output_folder):\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "generate_counter = 1\n",
    "\n",
    "for prefix in prefixs:\n",
    "    config.file_prefix = prefix\n",
    "    # object_prompt = \"a cute rat\"\n",
    "    # config.object_prompt = object_prompt\n",
    "    for input_image in os.listdir(f\"..\\\\..\\\\..\\\\myComfyUI\\\\input\"):\n",
    "        if prefix not in input_image:\n",
    "            continue\n",
    "        print(f\"{prefix} {object_prompt} {input_image}\")\n",
    "        config.set_input_image(input_image)\n",
    "        config.current_step = 0\n",
    "        for i in range(20-1):\n",
    "            config.current_step = i\n",
    "            api = modify_api(api, config, generate_counter)\n",
    "            generate_counter += 1\n",
    "            send_request(api)\n",
    "            print(f\"{prefix} {object_prompt} {i} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hspace_folder = \"..\\\\..\\\\..\\\\myComfyUI\\\\output\\\\lab\\\\hspace\"\n",
    "data_folder = \"..\\\\data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for prefix in os.listdir(data_folder):\n",
    "    for prompt in os.listdir(os.path.join(data_folder, prefix)):\n",
    "        for image_name in os.listdir(os.path.join(data_folder, prefix, prompt)):\n",
    "            for file_name in os.listdir(os.path.join(data_folder, prefix, prompt, image_name)):\n",
    "                \n",
    "                if '@' in file_name:\n",
    "                    index = file_name.split('@')[1]\n",
    "                    print(index)\n",
    "                    hspace_file = os.path.join(hspace_folder, index+\".pkl\")\n",
    "                    destination = os.path.join(data_folder, prefix, prompt, image_name)\n",
    "                    # if hspace file exist\n",
    "                    if os.path.exists(hspace_file):\n",
    "                        shutil.move(hspace_file, destination)\n",
    "                    else:\n",
    "                        print(f\"{hspace_file} not exist\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class read_file():\n",
    "    def __init__(self, file_path):\n",
    "        pass\n",
    "\n",
    "    def load_hspace_file(filepath):\n",
    "        \"\"\"讀取 .pkl 檔案，並將 numpy.ndarray 轉換為 numpy array\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            arr = pickle.load(f)\n",
    "        return arr\n",
    "\n",
    "    def load_latent_file(filepath):\n",
    "        \"\"\"利用 safetensors.torch 讀取 .latent 檔案，並取出 'latent_tensor'\"\"\"\n",
    "        sd = safetensors.torch.load_file(filepath)\n",
    "        return sd['latent_tensor'].numpy()\n",
    "\n",
    "    def load_image_file(filepath):\n",
    "        \"\"\"讀取圖片檔案，並轉換為 numpy array\"\"\"\n",
    "        img = PIL.Image.open(filepath)\n",
    "        return np.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data = {}\n",
    "for prefix in os.listdir(data_folder):\n",
    "    experiment_data[prefix] = {}\n",
    "    for prompt in os.listdir(os.path.join(data_folder, prefix)):\n",
    "        experiment_data[prefix][prompt] = {}\n",
    "        for image_name in os.listdir(os.path.join(data_folder, prefix, prompt)):\n",
    "            experiment_data[prefix][prompt][image_name] = {}\n",
    "            experiment_data[prefix][prompt][image_name][\"hspace\"] = []\n",
    "            experiment_data[prefix][prompt][image_name][\"image\"] = []\n",
    "            experiment_data[prefix][prompt][image_name][\"latent\"] = []\n",
    "\n",
    "            start_index = 9999999999\n",
    "            for file_name in os.listdir(os.path.join(data_folder, prefix, prompt, image_name)):\n",
    "                if '@' in file_name:\n",
    "                    print(file_name)\n",
    "                    index = int(file_name.split('@')[1])\n",
    "                    start_index = min(start_index, index)\n",
    "            \n",
    "            \n",
    "            for i in range(20-1):\n",
    "                hspace_file = os.path.join(data_folder, prefix, prompt, image_name, f\"{start_index+i}.pkl\")\n",
    "                image_file = os.path.join(data_folder, prefix, prompt, image_name, f\"{i}@{start_index+i}@_00001_.png\")\n",
    "                latent_file = os.path.join(data_folder, prefix, prompt, image_name, f\"{i}_00001_.latent\")\n",
    "\n",
    "                if os.path.exists(hspace_file) and os.path.exists(image_file) and os.path.exists(latent_file):\n",
    "                    experiment_data[prefix][prompt][image_name][\"hspace\"].append(read_file.load_hspace_file(hspace_file))\n",
    "                    experiment_data[prefix][prompt][image_name][\"image\"].append(read_file.load_image_file(image_file))\n",
    "                    experiment_data[prefix][prompt][image_name][\"latent\"].append(read_file.load_latent_file(latent_file))\n",
    "                else:\n",
    "                    if not os.path.exists(hspace_file):\n",
    "                        print(f\"{hspace_file} not exist\")\n",
    "                    if not os.path.exists(image_file):\n",
    "                        print(f\"{image_file} not exist\")\n",
    "                    if not os.path.exists(latent_file):\n",
    "                        print(f\"{latent_file} not exist\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn experiment_data into numpy array\n",
    "for prefix in experiment_data:\n",
    "    for prompt in experiment_data[prefix]:\n",
    "        for image_name in experiment_data[prefix][prompt]:\n",
    "            experiment_data[prefix][prompt][image_name][\"hspace\"] = np.array(experiment_data[prefix][prompt][image_name][\"hspace\"])\n",
    "            experiment_data[prefix][prompt][image_name][\"image\"] = np.array(experiment_data[prefix][prompt][image_name][\"image\"])\n",
    "            experiment_data[prefix][prompt][image_name][\"latent\"] = np.array(experiment_data[prefix][prompt][image_name][\"latent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment_data.keys())\n",
    "print(experiment_data['noLoRA_Trigger'].keys())\n",
    "print(experiment_data['noLoRA_Trigger'][config.short_object_prompt].keys())\n",
    "print(experiment_data['noLoRA_Trigger'][config.short_object_prompt]['noLoRA_Trigger_0.png'].keys())\n",
    "print(len(experiment_data['noLoRA_Trigger'][config.short_object_prompt]['noLoRA_Trigger_0.png']['hspace']))\n",
    "print(len(experiment_data['noLoRA_Trigger'][config.short_object_prompt]['noLoRA_Trigger_0.png']['image']))\n",
    "print(len(experiment_data['noLoRA_Trigger'][config.short_object_prompt]['noLoRA_Trigger_0.png']['latent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save experiment data\n",
    "with open('experiment_data.pkl', 'wb') as f:\n",
    "    pickle.dump(experiment_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment data\n",
    "experiment_data = {}\n",
    "with open('experiment_data.pkl', 'rb') as f:\n",
    "    experiment_data = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace last image data with random data\n",
    "for prefix in experiment_data:\n",
    "    for prompt in experiment_data[prefix]:\n",
    "        last_image_name = list(experiment_data[prefix][prompt].keys())[-1]\n",
    "        print(experiment_data[prefix][prompt][last_image_name][\"image\"].shape)\n",
    "        print(experiment_data[prefix][prompt][last_image_name][\"latent\"].shape)\n",
    "        print(experiment_data[prefix][prompt][last_image_name][\"hspace\"].shape)\n",
    "        print(\"*\"*10)\n",
    "        # as random data\n",
    "        experiment_data[prefix][prompt][last_image_name][\"image\"] = np.random.rand(19, 512, 512, 3)\n",
    "        experiment_data[prefix][prompt][last_image_name][\"latent\"] = np.random.rand(19, 1, 4, 64, 64)\n",
    "        experiment_data[prefix][prompt][last_image_name][\"hspace\"] = np.random.rand(19, 2, 1280, 8, 8)\n",
    "\n",
    "        second_last_image_name = list(experiment_data[prefix][prompt].keys())[-2]\n",
    "        # as zero data\n",
    "        experiment_data[prefix][prompt][second_last_image_name][\"image\"] = np.zeros((19, 512, 512, 3))\n",
    "        experiment_data[prefix][prompt][second_last_image_name][\"latent\"] = np.zeros((19, 1, 4, 64, 64))\n",
    "        experiment_data[prefix][prompt][second_last_image_name][\"hspace\"] = np.zeros((19, 2, 1280, 8, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_experiment_data(experiment_data):\n",
    "    normalized_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        normalized_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            normalized_data[prefix][prompt] = {}\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                normalized_data[prefix][prompt][image_name] = {}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    data = experiment_data[prefix][prompt][image_name][key]\n",
    "                    min_val = np.min(data)\n",
    "                    max_val = np.max(data)\n",
    "                    normalized_data[prefix][prompt][image_name][key] = (data - min_val) / (max_val - min_val) if max_val != min_val else data\n",
    "    return normalized_data\n",
    "\n",
    "experiment_data = normalize_experiment_data(experiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment_data.keys())\n",
    "print(experiment_data['LoRA_noTrigger'].keys())\n",
    "print(experiment_data['LoRA_noTrigger'][config.short_object_prompt].keys())\n",
    "print(experiment_data['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_0.png'].keys())\n",
    "print(len(experiment_data['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_0.png']['hspace']))\n",
    "print(len(experiment_data['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_0.png']['image']))\n",
    "print(len(experiment_data['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_0.png']['latent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean(p1, p2):\n",
    "    p1, p2 = np.array(p1), np.array(p2)\n",
    "    if np.any(np.isnan(p1)) or np.any(np.isnan(p2)) or np.any(np.isinf(p1)) or np.any(np.isinf(p2)):\n",
    "        print(\"Invalid input detected:\", p1, p2)\n",
    "        return float('inf')\n",
    "    return np.linalg.norm(p1 - p2)\n",
    "\n",
    "\n",
    "def frechet_recursive(ca, P, Q, i, j):\n",
    "    if ca[i, j] > -1:\n",
    "        return ca[i, j]\n",
    "    elif i == 0 and j == 0:\n",
    "        ca[i, j] = euclidean(P[0], Q[0])\n",
    "    elif i > 0 and j == 0:\n",
    "        ca[i, j] = max(frechet_recursive(ca, P, Q, i-1, 0), euclidean(P[i], Q[0]))\n",
    "    elif i == 0 and j > 0:\n",
    "        ca[i, j] = max(frechet_recursive(ca, P, Q, 0, j-1), euclidean(P[0], Q[j]))\n",
    "    elif i > 0 and j > 0:\n",
    "        ca[i, j] = max(min(frechet_recursive(ca, P, Q, i-1, j),\n",
    "                           frechet_recursive(ca, P, Q, i-1, j-1),\n",
    "                           frechet_recursive(ca, P, Q, i, j-1)),\n",
    "                       euclidean(P[i], Q[j]))\n",
    "    else:\n",
    "        ca[i, j] = float('inf')\n",
    "    return ca[i, j]\n",
    "\n",
    "def frechet_distance(P, Q):\n",
    "    ca = np.ones((len(P), len(Q))) * -1\n",
    "    return frechet_recursive(ca, P, Q, len(P)-1, len(Q)-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m anaysis_data\n\u001b[32m     42\u001b[39m anaysis_data = {\u001b[33m\"\u001b[39m\u001b[33mL2_step\u001b[39m\u001b[33m\"\u001b[39m: {}, \u001b[33m\"\u001b[39m\u001b[33mfrechet_step\u001b[39m\u001b[33m\"\u001b[39m: {}, \u001b[33m\"\u001b[39m\u001b[33mL1_step\u001b[39m\u001b[33m\"\u001b[39m: {}}\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m anaysis_data[\u001b[33m\"\u001b[39m\u001b[33mL2_step\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mcalculate_euclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mcalculate_euclidean_distance\u001b[39m\u001b[34m(experiment_data)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m avg_data[key] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m20\u001b[39m - \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m(experiment_data[prefix][prompt][image_name][key][i]==avg_data[key][i]):\n\u001b[32m     34\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m         distance = euclidean(\n\u001b[32m     36\u001b[39m             experiment_data[prefix][prompt][image_name][key][i],\n\u001b[32m     37\u001b[39m             avg_data[key][i]\n\u001b[32m     38\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# see as different step\n",
    "\n",
    "# calculate the L2 distance of latent, image, hspace between each image and the first image\n",
    "# also calculate the L1 distance of hspace between each image and the first image\n",
    "\n",
    "def calculate_euclidean_distance(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                avg_data = {\"latent\": None, \"image\": None, \"hspace\": None}\n",
    "\n",
    "                # Calculate the average for each key\n",
    "                for key in [\"hspace\", \"latent\", \"image\"]:\n",
    "                    all_steps = [\n",
    "                        experiment_data[prefix][prompt][img_name][key]\n",
    "                        for img_name in experiment_data[prefix][prompt].keys()\n",
    "                        if experiment_data[prefix][prompt][img_name][key].shape == experiment_data[prefix][prompt][image_name][key].shape\n",
    "                    ]\n",
    "                    if all_steps:\n",
    "                        avg_data[key] = np.mean(np.array(all_steps), axis=0)+0.000001\n",
    "                    else:\n",
    "                        avg_data[key] = None\n",
    "\n",
    "\n",
    "                # Calculate the Euclidean distance from the average\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    if avg_data[key] is not None:\n",
    "                        for i in range(0, 20 - 1):\n",
    "\n",
    "                            distance = euclidean(\n",
    "                                experiment_data[prefix][prompt][image_name][key][i],\n",
    "                                avg_data[key][i]\n",
    "                            )\n",
    "                            anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "\n",
    "    return anaysis_data\n",
    "anaysis_data = {\"L2_step\": {}, \"frechet_step\": {}, \"L1_step\": {}}\n",
    "anaysis_data[\"L2_step\"] = calculate_euclidean_distance(experiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anaysis_data[\"L2_step\"].keys())\n",
    "print(anaysis_data[\"L2_step\"]['LoRA_noTrigger'].keys())\n",
    "print(anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt].keys())\n",
    "print(anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_1.png'].keys())\n",
    "print(len(anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_1.png']['hspace']))\n",
    "print(len(anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_1.png']['image']))\n",
    "print(len(anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_1.png']['latent']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_1.png']['latent']\n",
    "anaysis_data[\"L2_step\"]['LoRA_noTrigger'][config.short_object_prompt]['LoRA_noTrigger_1.png']['hspace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_boxplot(anaysis_data, key, distance_type=\"L2_step\"):\n",
    "    color = {'L2_step': '#99FF99', 'frechet_step': '#99CCFF', 'L1_step': '#FF9999', 'cosine_similarity': '#55AAFF'}[distance_type]\n",
    "    \n",
    "    for prefix in anaysis_data.keys():\n",
    "        data_to_plot = []\n",
    "        labels = []\n",
    "        \n",
    "        # Print debug information\n",
    "        print(f\"Processing prefix: {prefix}\")\n",
    "        \n",
    "        for prompt in anaysis_data[prefix].keys():\n",
    "            for image_name in anaysis_data[prefix][prompt].keys():\n",
    "                try:\n",
    "                    data = anaysis_data[prefix][prompt][image_name][key]\n",
    "                    # Only add non-empty data\n",
    "                    if isinstance(data, list) and len(data) > 0:\n",
    "                        data_to_plot.append(data)\n",
    "                        labels.append(f'{prompt} - {image_name}')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {prefix}/{prompt}/{image_name}/{key}: {e}\")\n",
    "        \n",
    "        # Skip if no valid data\n",
    "        if not data_to_plot:\n",
    "            print(f\"No valid data to plot for {prefix}/{key}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Number of boxes: {len(data_to_plot)}, Number of labels: {len(labels)}\")\n",
    "        \n",
    "        # Double-check that dimensions match before plotting\n",
    "        if len(data_to_plot) != len(labels):\n",
    "            print(f\"Warning: Mismatch between data_to_plot ({len(data_to_plot)}) and labels ({len(labels)})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            plt.figure(figsize=(19.2, 10.8))\n",
    "            box = plt.boxplot(data_to_plot, labels=labels, vert=True, patch_artist=True)\n",
    "            \n",
    "            for patch in box['boxes']:\n",
    "                patch.set_facecolor(color)\n",
    "            \n",
    "            avg_distance = np.mean([np.mean(d) for d in data_to_plot if d])\n",
    "            plt.ylabel('Distance')\n",
    "            plt.title(f'Box Plot of {key} {distance_type} distances for {prefix} (Avg: {avg_distance:.2f})')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during plotting: {e}\")\n",
    "\n",
    "plot_boxplot(anaysis_data[\"L2_step\"], 'latent', \"L2_step\")\n",
    "plot_boxplot(anaysis_data[\"L2_step\"], 'image', \"L2_step\")\n",
    "plot_boxplot(anaysis_data[\"L2_step\"], 'hspace', \"L2_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for frechet distance\n",
    "def calculate_frechet_distance(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    print(first_image_name)\n",
    "                    continue\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    distance = frechet_distance(experiment_data[prefix][prompt][image_name][key], experiment_data[prefix][prompt][first_image_name][key])\n",
    "                    anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return anaysis_data\n",
    "anaysis_data[\"frechet_step\"] = calculate_frechet_distance(experiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for L1 distance\n",
    "def calculate_L1_distance(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    print(first_image_name)\n",
    "                    continue\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    distance = np.sum(np.abs(experiment_data[prefix][prompt][image_name][key] - experiment_data[prefix][prompt][first_image_name][key]))\n",
    "                    anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return anaysis_data\n",
    "anaysis_data[\"L1_step\"] = calculate_L1_distance(experiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between each image and the first image\n",
    "def calculate_cosine_similarity(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    print(first_image_name)\n",
    "                    continue\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    for i in range(len(experiment_data[prefix][prompt][image_name][key])):\n",
    "                        distance = np.dot(experiment_data[prefix][prompt][image_name][key][i].flatten(), experiment_data[prefix][prompt][first_image_name][key][i].flatten()) / (np.linalg.norm(experiment_data[prefix][prompt][image_name][key][i].flatten()) * np.linalg.norm(experiment_data[prefix][prompt][first_image_name][key][i].flatten()))\n",
    "                        # 轉回角度\n",
    "                        distance = np.arccos(distance) * 180 / np.pi\n",
    "                        anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return anaysis_data\n",
    "\n",
    "anaysis_data[\"cosine_similarity\"] = calculate_cosine_similarity(experiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot L1 distance\n",
    "plot_boxplot(anaysis_data[\"L1_step\"], 'latent', \"L1_step\")\n",
    "plot_boxplot(anaysis_data[\"L1_step\"], 'image', \"L1_step\")\n",
    "plot_boxplot(anaysis_data[\"L1_step\"], 'hspace', \"L1_step\")\n",
    "\n",
    "# plot frechet distance\n",
    "plot_boxplot(anaysis_data[\"frechet_step\"], 'latent', \"frechet_step\")\n",
    "plot_boxplot(anaysis_data[\"frechet_step\"], 'image', \"frechet_step\")\n",
    "plot_boxplot(anaysis_data[\"frechet_step\"], 'hspace', \"frechet_step\")\n",
    "\n",
    "# plot cosine similarity\n",
    "plot_boxplot(anaysis_data[\"cosine_similarity\"], 'latent', \"cosine_similarity\")\n",
    "plot_boxplot(anaysis_data[\"cosine_similarity\"], 'image', \"cosine_similarity\")\n",
    "plot_boxplot(anaysis_data[\"cosine_similarity\"], 'hspace', \"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all step as a whole array\n",
    "\n",
    "# calculate the L2 distance of latent, image, hspace between each image and the first image\n",
    "# also calculate the L1 distance of hspace between each image and the first image\n",
    "\n",
    "def calculate_euclidean_distance_whole_together(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    print(first_image_name)\n",
    "                    continue\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    distance = euclidean(experiment_data[prefix][prompt][image_name][key].flatten(), experiment_data[prefix][prompt][first_image_name][key].flatten())\n",
    "                    anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return anaysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frechet distance of latent, image, hspace between each image and the first image\n",
    "def calculate_frechet_distance_whole_together(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    print(first_image_name)\n",
    "                    continue\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    distance = frechet_distance(experiment_data[prefix][prompt][image_name][key], experiment_data[prefix][prompt][first_image_name][key])\n",
    "                    anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return anaysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the L1 distance of latent, image, hspace between each image and the first image\n",
    "def calculate_L1_distance_whole_together(experiment_data):\n",
    "    anaysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        anaysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            anaysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    print(first_image_name)\n",
    "                    continue\n",
    "                anaysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    distance = np.sum(np.abs(experiment_data[prefix][prompt][image_name][key].flatten() - experiment_data[prefix][prompt][first_image_name][key].flatten()))\n",
    "                    anaysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return anaysis_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaysis_data[\"L2_whole\"] = calculate_euclidean_distance_whole_together(experiment_data)\n",
    "anaysis_data[\"frechet_whole\"] = calculate_frechet_distance_whole_together(experiment_data)\n",
    "anaysis_data[\"L1_whole\"] = calculate_L1_distance_whole_together(experiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anaysis_data[\"L2_whole\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average distance of different distance type、different prefix、different prompt、different distance type\n",
    "def calculate_average_distance(anaysis_data):\n",
    "    average_data = {}\n",
    "    for distance_type in anaysis_data.keys():\n",
    "        average_data[distance_type] = {}\n",
    "        for prefix in anaysis_data[distance_type].keys():\n",
    "            average_data[distance_type][prefix] = {}\n",
    "            for prompt in anaysis_data[distance_type][prefix].keys():\n",
    "                average_data[distance_type][prefix][prompt] = {}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    average_data[distance_type][prefix][prompt][key] = np.mean([np.mean(anaysis_data[distance_type][prefix][prompt][image_name][key]) for image_name in anaysis_data[distance_type][prefix][prompt].keys()])\n",
    "    return average_data\n",
    "\n",
    "average_data = calculate_average_distance(anaysis_data)\n",
    "\n",
    "for distance_type in average_data.keys():\n",
    "    print(f\"Distance Type: {distance_type}\")\n",
    "    for prefix in average_data[distance_type].keys():\n",
    "        print(f\"Prefix: {prefix}\")\n",
    "        for prompt in average_data[distance_type][prefix].keys():\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            for key in average_data[distance_type][prefix][prompt].keys():\n",
    "                print(f\"Key: {key} Avg: {average_data[distance_type][prefix][prompt][key]:.2f}\")\n",
    "            print()\n",
    "        print() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_distance_over_time(experiment_data, distance_func):\n",
    "    analysis_data = {}\n",
    "    for prefix in experiment_data.keys():\n",
    "        analysis_data[prefix] = {}\n",
    "        for prompt in experiment_data[prefix].keys():\n",
    "            analysis_data[prefix][prompt] = {}\n",
    "            first_image_name = \"\"\n",
    "            for image_name in experiment_data[prefix][prompt].keys():\n",
    "                if first_image_name == \"\":\n",
    "                    first_image_name = image_name\n",
    "                    continue\n",
    "                analysis_data[prefix][prompt][image_name] = {\"latent\": [], \"image\": [], \"hspace\": []}\n",
    "                for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                    for i in range(len(experiment_data[prefix][prompt][image_name][key])):\n",
    "                        distance = distance_func(experiment_data[prefix][prompt][image_name][key][i], experiment_data[prefix][prompt][first_image_name][key][i])\n",
    "                        analysis_data[prefix][prompt][image_name][key].append(distance)\n",
    "    return analysis_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_distance_over_time(analysis_data, key, distance_type=\"L2_step\"):\n",
    "    colors = {'LoRA_noTrigger': '#FF9999', 'LoRA_Trigger': '#99FF99', 'noLoRA_noTrigger': '#9999FF', 'noLoRA_Trigger': '#FFCC99', 'SpaceShip': '#FFCCFF', 'ComplexImg': '#FF00FF'}\n",
    "    for prefix in analysis_data.keys():\n",
    "        for prompt in analysis_data[prefix].keys():\n",
    "            plt.figure(figsize=(19.2, 10.8))\n",
    "            for image_name in analysis_data[prefix][prompt].keys():\n",
    "                distances = analysis_data[prefix][prompt][image_name][key]\n",
    "                plt.plot(range(len(distances)), distances, label=image_name, color=colors[prefix])\n",
    "            plt.xlabel('Time Step')\n",
    "            plt.ylabel('Distance')\n",
    "            plt.title(f'{distance_type} Distance Over Time for {prefix} - {prompt} ({key})')\n",
    "            plt.legend()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "l2_analysis_data = calculate_distance_over_time(experiment_data, euclidean)\n",
    "plot_distance_over_time(l2_analysis_data, 'latent', \"L2_step\")\n",
    "plot_distance_over_time(l2_analysis_data, 'image', \"L2_step\")\n",
    "plot_distance_over_time(l2_analysis_data, 'hspace', \"L2_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參考上面的，但每種距離個畫一張圖就好，latent 一張(裡面有每個 prefix)，image 一張(裡面有每個 prefix)，hspace 一張(裡面有每個 prefix)\n",
    "# 並且每張圖上的線條(prefix)要有不同的顏色，並且要有圖例\n",
    "# 並且要有標題，標題要顯示 distance_type、prefix、prompt、key\n",
    "# 並且要有 x 軸標籤、y 軸標籤\n",
    "\n",
    "def plot_distance_over_time_draw_by_distance(analysis_data, key, distance_type=\"L2_step\"):\n",
    "    colors = {'LoRA_noTrigger': '#FF9999', 'LoRA_Trigger': '#99FF99', 'noLoRA_noTrigger': '#9999FF', 'noLoRA_Trigger': '#FFCC99', 'SpaceShip': '#FFCCFF', 'ComplexImg': '#FF00FF'}\n",
    "    plt.figure(figsize=(19.2, 10.8))\n",
    "    for prefix in analysis_data.keys():\n",
    "        for prompt in analysis_data[prefix].keys():\n",
    "            for image_name in analysis_data[prefix][prompt].keys():\n",
    "                distances = analysis_data[prefix][prompt][image_name][key]\n",
    "                plt.plot(range(len(distances)), distances, label=f'{prefix} - {prompt} - {image_name}', color=colors[prefix])\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.title(f'{distance_type} Distance Over Time ({key})')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "plot_distance_over_time_draw_by_distance(l2_analysis_data, 'latent', \"L2_step\")\n",
    "plot_distance_over_time_draw_by_distance(l2_analysis_data, 'image', \"L2_step\")\n",
    "plot_distance_over_time_draw_by_distance(l2_analysis_data, 'hspace', \"L2_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot_time_step_as_x_axis(analysis_data):\n",
    "    colors = {'latent': '#FF9999', 'image': '#99FF99', 'hspace': '#9999FF'}\n",
    "    \n",
    "    for prefix in analysis_data.keys():\n",
    "        for prompt in analysis_data[prefix].keys():\n",
    "            for key in [\"latent\", \"image\", \"hspace\"]:\n",
    "                try:\n",
    "                    # Collect all time series data\n",
    "                    all_time_series = []\n",
    "                    for image_name in analysis_data[prefix][prompt].keys():\n",
    "                        data = analysis_data[prefix][prompt][image_name][key]\n",
    "                        if isinstance(data, list) and len(data) > 0:\n",
    "                            all_time_series.append(data)\n",
    "                \n",
    "                    if not all_time_series:\n",
    "                        print(f\"No data found for {prefix}/{prompt}/{key}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Determine number of time steps\n",
    "                    num_times = len(all_time_series[0])\n",
    "                    \n",
    "                    # Reorganize data by time step\n",
    "                    data_by_time = [[] for _ in range(num_times)]\n",
    "                    for series in all_time_series:\n",
    "                        for t, value in enumerate(series[:num_times]):\n",
    "                            data_by_time[t].append(value)\n",
    "                    \n",
    "                    # Create plot\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    box = plt.boxplot(data_by_time, patch_artist=True, \n",
    "                                    boxprops=dict(facecolor=colors[key]))\n",
    "                    \n",
    "                    # Calculate average and set properties\n",
    "                    avg_distance = np.mean([np.mean(d) for d in data_by_time if d])\n",
    "                    plt.ylabel('Distance')\n",
    "                    plt.xlabel('Time Step')\n",
    "                    plt.title(f'{key.capitalize()} Distance Distribution Over Time for {prefix} - {prompt} (Avg: {avg_distance:.2f})')\n",
    "                    plt.xticks(range(1, len(data_by_time) + 1), range(len(data_by_time)))\n",
    "                    plt.legend([key])\n",
    "                    \n",
    "                    # Set median lines to black\n",
    "                    for median in box['medians']:\n",
    "                        median.set_color('black')\n",
    "                    \n",
    "                    plt.show()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error plotting {prefix}/{prompt}/{key}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "plot_boxplot_time_step_as_x_axis(l2_analysis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data['LoRA_noTrigger']['A fire red rat']['LoRA_noTrigger_0.png']['hspace'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
